# Calculating and visualizing term frequency for Chinese documents

* Collecting at least 100 Chinese documents. High homogeneity among documents is preferred. 
* Loading them to a dataframe and using `unnest_tokens()` of `tidytext` package to segment documents into words
